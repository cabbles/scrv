{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4961e3ed-11b9-4542-9df4-1dc90dfc4bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.4.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mmm\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, hf-xet, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed fsspec-2025.7.0 hf-xet-1.1.5 huggingface-hub-0.33.4 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.2 tqdm-4.67.1 transformers-4.53.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.24.1)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.15.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.33.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.7.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.1/367.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-1.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#holay molay :0 ヾ(＠⌒ー⌒＠)ノ  ╚(•⌂•)╝   (≧∀≦)ゞ\n",
    "#finish:\n",
    "#min p add ✓\n",
    "#fix sample nexttoken ✓\n",
    "#logtoku detection\n",
    "###adapt get_eu for per-token basis ✓\n",
    "###implement R_token = -AU_token * EU_token ✓\n",
    "###logtoku fucntion(create sliding window evaluating r_response = (1/K) Σ R(aₜ) )\n",
    "#verify generation loop works ✓\n",
    "#verify hallucination detection works (⊙_⊙;)\n",
    "!pip install transformers\n",
    "!pip install scipy\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b41d7fc-fd97-4751-b292-03a644f1cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.special import softmax, digamma\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gc\n",
    "import random\n",
    "\n",
    "#chatgpt said this would get rid of variation when greedy decoding\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c77ab3f-d66c-4bd0-8da6-68278e6d899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topk, \n",
    "#get_uncertainty_metric (renamed from get_eu), \n",
    "#get_one_pass_metric for logtoku pasted from their codebase\n",
    "\n",
    "def topk(arr, k):\n",
    "    indices = np.argpartition(arr, -k)[-k:]\n",
    "    values = arr[indices]\n",
    "    return values, indices\n",
    "    \n",
    "def get_uncertainty_metric(logits, mode=\"eu\", k=25):\n",
    "    if mode == \"eu\":\n",
    "        if k is None:\n",
    "            raise ValueError(\"k must be provided for 'eu' mode.\")\n",
    "\n",
    "        def eu(logits):\n",
    "            top_k = k\n",
    "            if len(logits) < top_k:\n",
    "                raise ValueError(f\"Logits array length ({len(logits)}) is less than top_k (= {k}). \\nLogits shape: {logits.shape}, first 10 logits: {logits.squeeze(0).cpu().numpy()[:10]}\")\n",
    "            top_values, _ = topk(logits, top_k)\n",
    "            mean_scores = top_k / (np.sum(np.maximum(0, top_values)) + top_k)\n",
    "            return mean_scores\n",
    "        return eu\n",
    "\n",
    "    \n",
    "    elif mode == \"au\":\n",
    "        def cal_au(logits):\n",
    "            top_k = k\n",
    "            if len(logits) < top_k:\n",
    "                raise ValueError(\"Logits array length is less than top_k.\")\n",
    "            top_values = np.partition(logits, -top_k)[-top_k:]\n",
    "            alpha = np.array([top_values])\n",
    "            alpha_0 = alpha.sum(axis=1, keepdims=True)\n",
    "            psi_alpha_k_plus_1 = digamma(alpha + 1)\n",
    "            psi_alpha_0_plus_1 = digamma(alpha_0 + 1)\n",
    "            result = - (alpha / alpha_0) * (psi_alpha_k_plus_1 - psi_alpha_0_plus_1)\n",
    "            print(f\"k = {k}\")\n",
    "            return result.sum(axis=1)[0]\n",
    "        return cal_au\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported mode: {mode}\")\n",
    "\n",
    "def get_token_reliability(logits, k=25, token=None):\n",
    "    au_fn = get_uncertainty_metric(logits, mode= \"au\", k=k)\n",
    "    eu_fn = get_uncertainty_metric(logits, mode= \"eu\", k=k)   \n",
    "    au = au_fn(logits)\n",
    "    eu = eu_fn(logits)\n",
    "    print(f\"token: {token} | au: {au}, eu: {eu}| rel.: {-au * eu}\")\n",
    "    return -au * eu\n",
    "\n",
    "\n",
    "#unused so far?\n",
    "def get_one_pass_metric(logits, clean_generated_tokens_length, metrics, get_eu, topk):\n",
    "    \"\"\"\n",
    "    Process logits, calculate various metrics, and extract topk information from the logits.\n",
    "    \n",
    "    Args:\n",
    "        \n",
    "        clean_generated_tokens_length (int): Length of the generated tokens.\n",
    "        metrics (list): List of metrics and their parameters.\n",
    "        get_eu (function): Function to retrieve metric values.\n",
    "        topk (function): Function to extract topk values.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing metric_dict and logit_dict.\n",
    "    \"\"\"\n",
    "    metric_dict = {}\n",
    "\n",
    "    sequence_length = len(logits)\n",
    "    for idx_l in range(min(clean_generated_tokens_length, sequence_length)):\n",
    "        logit = logits[idx_l]\n",
    "        logit = logit.cpu().numpy()\n",
    "        \n",
    "        for metric, k in metrics:\n",
    "            if metric not in metric_dict:\n",
    "                metric_dict[metric] = []\n",
    "            eu = get_eu(metric, k)\n",
    "            metric_dict[metric].append(eu(logit[0]))\n",
    "\n",
    "    logit_dict = {}\n",
    "    logit_start_idx = 0\n",
    "    logit_end_idx = min(clean_generated_tokens_length, sequence_length)\n",
    "    ii = 0\n",
    "\n",
    "    # Extract topk information from logits\n",
    "    for idx_ll in range(logit_start_idx, logit_end_idx):\n",
    "        logit = logits[idx_ll]\n",
    "        logit = logit.cpu().numpy()\n",
    "        \n",
    "        top_k = 10\n",
    "        top_values, top_indices = topk(logit[0], top_k)\n",
    "        \n",
    "        logit_dict[ii] = {'top_values': top_values, 'top_indices': top_indices}\n",
    "        ii += 1\n",
    "\n",
    "    # Convert top_values and top_indices in logit_dict to list\n",
    "    for key in logit_dict:\n",
    "        logit_dict[key]['top_values'] = logit_dict[key]['top_values'].tolist()\n",
    "        logit_dict[key]['top_indices'] = logit_dict[key]['top_indices'].tolist()\n",
    "\n",
    "    return metric_dict, logit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd12628a-f5a5-443e-b5ea-955797626ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380742e2dca74bee9d2c999d0bbb4002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "if \"generator\" in globals():\n",
    "    if hasattr(generator, \"model\"):\n",
    "        del generator.model\n",
    "    if hasattr(generator, \"tokenizer\"):\n",
    "        del generator.tokenizer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "class SemanticSpillway:\n",
    "    def __init__(self, model_path: str = \"../models/Llama-3.1-8B-Instruct\"):\n",
    "        self.device = torch.device(\"cuda\")# if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path, \n",
    "            torch_dtype=torch.float16, \n",
    "            local_files_only=True\n",
    "        ).to(self.device)\n",
    "        self.reliability_scores = [] #for logtoku\n",
    "\n",
    "        #not necessary unless/until we do processing in batches(then have to do padding and attention masks and blah blah blah)\n",
    "        # if self.tokenizer.pad_token is None:\n",
    "        #     self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    # (currently) uses min p to sample next token\n",
    "    def sample_next_token(self, logits, temperature=0.7, top_k=50, top_p=0.9, min_p = 0.05, min_tokens_to_keep = 5, do_sample=True, k=25):\n",
    "        \n",
    "        # Temperature\n",
    "        logits = logits / temperature\n",
    "        \n",
    "        # # top-k \n",
    "        # if top_k > 0:\n",
    "        #     top_k = min(top_k, logits.size(-1))\n",
    "        #     indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        #     logits[indices_to_remove] = float('-inf')\n",
    "        \n",
    "        # # top-p \n",
    "        # if top_p < 1.0:\n",
    "        #     sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        #     cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "        #     sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        #     sorted_indices_to_remove[..., 0] = 0\n",
    "        #     indices_to_remove = sorted_indices_to_remove.scatter(-1, sorted_indices, sorted_indices_to_remove)\n",
    "        #     logits[indices_to_remove] = float('-inf')\n",
    "\n",
    "        \n",
    "        # min-p truncation: gets rid of tokens w/ probabilities less than min_p * max_prob (ie probability of most likely token)\n",
    "        # pasted from paper\n",
    "        # turn into methods later i dislike this block of code\n",
    "        # Convert logits to probabilities\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        # Get the probability of the top token for each sequence in the batch\n",
    "        top_probs, _ = probs.max(dim=-1, keepdim=True)\n",
    "        # Calculate the actual min_p threshold by scaling min_p with the top token's probability\n",
    "        scaled_min_p = min_p * top_probs\n",
    "        # Create a mask for tokens that have a probability less than the scaled min_p\n",
    "        tokens_to_remove = probs < scaled_min_p\n",
    "\n",
    "        sorted_indices = torch.argsort(logits, descending=True, dim=-1)\n",
    "        sorted_indices_to_remove = torch.gather(tokens_to_remove, dim=-1, index=sorted_indices)\n",
    "        # Keep at least min_tokens_to_keep\n",
    "        sorted_indices_to_remove[..., : min_tokens_to_keep] = False\n",
    "\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
    "        filter_value = float('-inf') #TODO verify that this is the correct value to use\n",
    "        scores_processed = logits.masked_fill(indices_to_remove, filter_value)\n",
    "        \n",
    "        # sample or greedy\n",
    "        if do_sample:\n",
    "            probs = torch.softmax(scores_processed, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            next_token = torch.argmax(scores_processed, dim=-1, keepdim=True)\n",
    "            #next_token = torch.argmax(logits, dim=-1).unsqueeze(0)\n",
    "        return next_token\n",
    "\n",
    "    # main generation loop w/ stopping control\n",
    "    # halu_detect = which function to use for hallucination control. currently only option is logtoku, but for regeneration, ner + logtoku function will be created to use instead\n",
    "    def generation_loop(self, prompt, max_new_tokens=100, temperature=1.0, top_k=50, top_p=0.9, min_p = 0.05, \n",
    "                 k=25, do_sample=True, halu_detect=None):\n",
    "\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        #turn text into token ids\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        #input_ids = input_ids.long()\n",
    "        \n",
    "        for step in range(max_new_tokens):\n",
    "            with torch.no_grad(): #.no_grad to ignore gradients for inference\n",
    "                \n",
    "                outputs = self.model(input_ids)\n",
    "                logits = outputs.logits[:, -1, :]\n",
    "                \n",
    "                # sample next token\n",
    "                next_token = self.sample_next_token(logits, temperature,  do_sample)\n",
    "                \n",
    "                # # check for end of sequence -- if it is, end loop\n",
    "                if next_token == self.tokenizer.eos_token_id:\n",
    "                    print(\"found an eos\")\n",
    "                    break\n",
    "                #or\n",
    "                if next_token in self.tokenizer.encode(\"<|endoftext|>\"):\n",
    "                    print(\"found an eos\")\n",
    "                    break\n",
    "                \n",
    "                # add new token to sequence\n",
    "                input_ids = torch.cat([input_ids, next_token], dim=-1) \n",
    "\n",
    "                \n",
    "                # callback fn to implement hallucination detection for stopping generation\n",
    "                # if fn exists and returns false (aka hallucination is detected), stop generating \n",
    "                logits_1d = logits.squeeze(0).cpu().numpy()\n",
    "                token_str = self.tokenizer.decode(next_token.item())\n",
    "                if halu_detect and not halu_detect(step, self.reliability_scores, logits_1d, k, token_str):\n",
    "                    break\n",
    "                    \n",
    "        #turn token ids back into clean text\n",
    "        return self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "\n",
    "# returns true if no hallucination detected (clean), returns false if not\n",
    "# used as callback in greater generation loop (intended for initial generation)\n",
    "def logtoku(step, reliability_scores, logits, k=25, token=None):\n",
    "    tok_rel = get_token_reliability(logits, k, token)\n",
    "    #print(f\"token reliability: {tok_rel}\")\n",
    "    # if step >=20:\n",
    "    #     print(\"Hallucination detected... ceasing generation.\")\n",
    "    #     return False\n",
    "    return True\n",
    "\n",
    "# returns true if no hallucination detected (clean), returns false if not\n",
    "# used as callback in greater generation loop (intended for comparing with retrieved context)\n",
    "def ner_based():\n",
    "    #empty function to fill in later\n",
    "    return True\n",
    "\n",
    "#combining the above methods to use at once?!（⊙ｏ⊙）\n",
    "def ner_logtoku():\n",
    "    #empty\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "generator = SemanticSpillway(\"../models/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b92abe-9bd9-4c97-9f32-f76e694a970e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated: 14.96 GB\n",
      "GPU memory cached: 15.08 GB\n",
      "GPU memory available: 23.54 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  15316 MiB |  15316 MiB |  15316 MiB |      0 B   |\\n|       from large pool |  15316 MiB |  15316 MiB |  15316 MiB |      0 B   |\\n|       from small pool |      0 MiB |      0 MiB |      0 MiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  15316 MiB |  15316 MiB |  15316 MiB |      0 B   |\\n|       from large pool |  15316 MiB |  15316 MiB |  15316 MiB |      0 B   |\\n|       from small pool |      0 MiB |      0 MiB |      0 MiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |  15316 MiB |  15316 MiB |  15316 MiB |      0 B   |\\n|       from large pool |  15316 MiB |  15316 MiB |  15316 MiB |      0 B   |\\n|       from small pool |      0 MiB |      0 MiB |      0 MiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  15446 MiB |  15446 MiB |  15446 MiB |      0 B   |\\n|       from large pool |  15444 MiB |  15444 MiB |  15444 MiB |      0 B   |\\n|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory | 132599 KiB | 140816 KiB | 395256 KiB | 262656 KiB |\\n|       from large pool | 131072 KiB | 139264 KiB | 393216 KiB | 262144 KiB |\\n|       from small pool |   1527 KiB |   2040 KiB |   2040 KiB |    512 KiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     292    |     292    |     292    |       0    |\\n|       from large pool |     226    |     226    |     226    |       0    |\\n|       from small pool |      66    |      66    |      66    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     292    |     292    |     292    |       0    |\\n|       from large pool |     226    |     226    |     226    |       0    |\\n|       from small pool |      66    |      66    |      66    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     195    |     195    |     195    |       0    |\\n|       from large pool |     194    |     194    |     194    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      33    |      33    |      33    |       0    |\\n|       from large pool |      32    |      32    |      32    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Check current GPU memory usage\n",
    "print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"GPU memory cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "print(f\"GPU memory available: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "# See what's taking up memory\n",
    "torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46647ba-771a-43bc-85fa-3e0398cd6b3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test generation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuestion: What is the capital of France? Answer:  \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[11], line 118\u001b[0m, in \u001b[0;36mSemanticSpillway.generation_loop\u001b[0;34m(self, prompt, max_new_tokens, temperature, top_k, top_p, min_p, k, do_sample, halu_detect)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# callback fn to implement hallucination detection for stopping generation\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# if fn exists and returns false (aka hallucination is detected), stop generating \u001b[39;00m\n\u001b[1;32m    117\u001b[0m logits_1d \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 118\u001b[0m token_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m halu_detect \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m halu_detect(step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreliability_scores, logits_1d, k, token_str):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3841\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3838\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3839\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py:682\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    681\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 682\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    685\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    688\u001b[0m )\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# test generation\n",
    "result = generator.generation_loop(\"Question: What is the capital of France? Answer:  \", max_new_tokens=100, temperature=0.8, do_sample=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b462d9e-8174-41f8-82ce-dcd870faa274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7\n",
      "token:  The | au: 1.9106452525172894, eu: 0.06722689075630252| rel.: -0.12844673966502787\n",
      "k = 7\n",
      "token:  treaty | au: 1.9109331796550468, eu: 0.06096897114861187| rel.: -0.1165076298973137\n",
      "k = 7\n",
      "token:  recognized | au: 1.9164330292272105, eu: 0.06378132118451026| rel.: -0.12223263056574464\n",
      "k = 7\n",
      "token:  Cherokee | au: 1.912704435718499, eu: 0.06232609905397885| rel.: -0.1192114061215759\n",
      "k = 7\n",
      "token:  sovereignty | au: 1.9143519309094599, eu: 0.06080347448425624| rel.: -0.11639924878494001\n",
      "k = 7\n",
      "token:  and | au: 1.9170154611521495, eu: 0.056338028169014086| rel.: -0.10800087105082533\n",
      "k = 7\n",
      "token:  established | au: 1.9135632322258205, eu: 0.06666666666666667| rel.: -0.12757088214838802\n",
      "k = 7\n",
      "token:  a | au: 1.9121819585440236, eu: 0.06565064478311841| rel.: -0.12553597852106135\n",
      "k = 7\n",
      "token:  boundary | au: 1.9161235264691614, eu: 0.06526806526806526| rel.: -0.12506167538726462\n",
      "k = 7\n",
      "token:  between | au: 1.9142026327573574, eu: 0.06086956521739131| rel.: -0.1165166819939261\n",
      "k = 7\n",
      "token:  the | au: 1.914859818450589, eu: 0.05717202654415518| rel.: -0.10947641636879324\n",
      "k = 7\n",
      "token:  Cherokee | au: 1.9141050886953437, eu: 0.058916359810625984| rel.: -0.11277210412092503\n",
      "k = 7\n",
      "token:  Nation | au: 1.9149881879766464, eu: 0.055944055944055944| rel.: -0.10713220632037182\n",
      "k = 7\n",
      "token:  and | au: 1.906808899933499, eu: 0.06201550387596899| rel.: -0.11825171472455807\n",
      "k = 7\n",
      "token:  the | au: 1.9146506696338705, eu: 0.05845511482254697| rel.: -0.11192112473851434\n",
      "k = 7\n",
      "token:  state | au: 1.9163943181538796, eu: 0.058577405857740586| rel.: -0.11225740775796784\n",
      "k = 7\n",
      "token:  of | au: 1.904632849005194, eu: 0.06215316315205328| rel.: -0.11837895620897988\n",
      "k = 7\n",
      "token:  Michigan | au: 1.919007420010139, eu: 0.05211726384364821| rel.: -0.10001341602658706\n",
      "k = 7\n",
      "token: . | au: 1.9154082035429538, eu: 0.05970149253731343| rel.: -0.11435272856972858\n",
      "k = 7\n",
      "token:  It | au: 1.9123297062493974, eu: 0.06702573309395571| rel.: -0.12817530047871484\n",
      "k = 7\n",
      "token:  also | au: 1.9109558028254419, eu: 0.06040992448759439| rel.: -0.11544069574781526\n",
      "k = 7\n",
      "token:  provided | au: 1.9178138353371676, eu: 0.059353471118177| rel.: -0.11382890808572484\n",
      "k = 7\n",
      "token:  for | au: 1.912407334884929, eu: 0.05876180482686254| rel.: -0.11237650656196854\n",
      "k = 7\n",
      "token:  trade | au: 1.9132229829765017, eu: 0.06274509803921569| rel.: -0.12004536363774128\n",
      "k = 7\n",
      "token:  and | au: 1.915537603040218, eu: 0.056| rel.: -0.10727010577025221\n",
      "k = 7\n",
      "token:  commerce | au: 1.9156901141016571, eu: 0.060935799782372145| rel.: -0.11673410923796823\n",
      "k = 7\n",
      "token:  between | au: 1.9154750746337346, eu: 0.05517241379310345| rel.: -0.10568138342806811\n",
      "k = 7\n",
      "token:  the | au: 1.9079412051276652, eu: 0.05761316872427984| rel.: -0.10992253856702598\n",
      "k = 7\n",
      "token:  two | au: 1.9162034759086592, eu: 0.05431619786614937| rel.: -0.10408088714925792\n",
      "k = 7\n",
      "token:  parties | au: 1.9175822452255724, eu: 0.057230454777721| rel.: -0.10974410396794282\n",
      "k = 7\n",
      "token: . | au: 1.9127550332196885, eu: 0.05583250249252243| rel.: -0.10679390015982308\n",
      "k = 7\n",
      "token:  Additionally | au: 1.9149009622062052, eu: 0.06492753623188406| rel.: -0.12432980160411304\n",
      "k = 7\n",
      "token: , | au: 1.9010180786898891, eu: 0.06349206349206349| rel.: -0.12069956055173899\n",
      "k = 7\n",
      "token:  the | au: 1.9061355100912691, eu: 0.05720122574055159| rel.: -0.10903328760481214\n",
      "k = 7\n",
      "token:  treaty | au: 1.9130050558151972, eu: 0.056622851365015166| rel.: -0.10831980093594645\n",
      "k = 7\n",
      "token:  established | au: 1.918484930071452, eu: 0.058823529411764705| rel.: -0.1128520547100854\n",
      "k = 7\n",
      "token:  a | au: 1.908407153355686, eu: 0.060836501901140684| rel.: -0.11610081541327366\n",
      "k = 7\n",
      "token:  system | au: 1.9172298018782683, eu: 0.06037735849056604| rel.: -0.1157572710568011\n",
      "k = 7\n",
      "token:  for | au: 1.9032997106385878, eu: 0.054982817869415807| rel.: -0.10464878134095328\n",
      "k = 7\n",
      "token:  resolving | au: 1.9128631285658217, eu: 0.05894736842105263| rel.: -0.11275824757861685\n",
      "k = 7\n",
      "token:  disputes | au: 1.9141923544594908, eu: 0.05418480890179003| rel.: -0.10372014692765504\n",
      "k = 7\n",
      "token:  between | au: 1.912127286464834, eu: 0.051094890510948905| rel.: -0.09769993434491853\n",
      "k = 7\n",
      "token:  the | au: 1.9112812104699528, eu: 0.05353728489483748| rel.: -0.1023248066790797\n",
      "k = 7\n",
      "token:  Cherokee | au: 1.916775523804822, eu: 0.051094890510948905| rel.: -0.09793743552287412\n",
      "k = 7\n",
      "token:  Nation | au: 1.9043597279434306, eu: 0.053614169459071326| rel.: -0.10210066516499006\n",
      "k = 7\n",
      "token:  and | au: 1.8998838649139749, eu: 0.061504667764964306| rel.: -0.11685172590355035\n",
      "k = 7\n",
      "token:  the | au: 1.9171402695155342, eu: 0.05166051660516605| rel.: -0.09904045672773977\n",
      "k = 7\n",
      "token:  United | au: 1.9183121066335085, eu: 0.050724637681159424| rel.: -0.09730568656836638\n",
      "k = 7\n",
      "token:  States | au: 1.8972433933590989, eu: 0.05848563968668407| rel.: -0.11096149350194207\n",
      "k = 7\n",
      "token: . | au: 1.9180140270222115, eu: 0.051329055912007336| rel.: -0.09844984923303744\n",
      "k = 7\n",
      "token:  However | au: 1.914140879908294, eu: 0.06698564593301436| rel.: -0.12821996324744553\n",
      "k = 7\n",
      "token: , | au: 1.9016208343275582, eu: 0.06211869107043816| rel.: -0.11812619714070245\n",
      "k = 7\n",
      "token:  the | au: 1.9171988759072154, eu: 0.055776892430278883| rel.: -0.10693539546892834\n",
      "k = 7\n",
      "token:  treaty | au: 1.910609755070977, eu: 0.0611353711790393| rel.: -0.11680583655455755\n",
      "k = 7\n",
      "token:  did | au: 1.9212612132766202, eu: 0.0527803958529689| rel.: -0.10140492737369532\n",
      "k = 7\n",
      "token:  not | au: 1.9075157635276563, eu: 0.05702647657841141| rel.: -0.10877890301176045\n",
      "k = 7\n",
      "token:  address | au: 1.9195801519396523, eu: 0.05555555555555555| rel.: -0.10664334177442512\n",
      "k = 7\n",
      "token:  the | au: 1.914912946404471, eu: 0.05648008068582955| rel.: -0.10815443771926411\n",
      "k = 7\n",
      "token:  issue | au: 1.9157354162869054, eu: 0.06040992448759439| rel.: -0.11572943183610217\n",
      "k = 7\n",
      "token:  of | au: 1.895004185711536, eu: 0.061878453038674036| rel.: -0.11725992751364202\n",
      "k = 7\n",
      "token:  slavery | au: 1.9184958608904388, eu: 0.05818181818181818| rel.: -0.11162157736089826\n",
      "k = 7\n",
      "token: , | au: 1.9219346545663067, eu: 0.04741744284504657| rel.: -0.09113322663481217\n",
      "k = 7\n",
      "token:  which | au: 1.914778802982237, eu: 0.051756007393715345| rel.: -0.09910130588447807\n",
      "k = 7\n",
      "token:  was | au: 1.921052322328813, eu: 0.04912280701754386| rel.: -0.09436748250036274\n",
      "k = 7\n",
      "token:  a | au: 1.9055064812513667, eu: 0.057672502574665295| rel.: -0.10989532744601085\n",
      "k = 7\n",
      "token:  contentious | au: 1.9190733139672278, eu: 0.04890829694323144| rel.: -0.0938586074953404\n",
      "k = 7\n",
      "token:  issue | au: 1.9137608772539645, eu: 0.0498220640569395| rel.: -0.09534751701621175\n",
      "k = 7\n",
      "token:  between | au: 1.921413381455759, eu: 0.046473029045643155| rel.: -0.08929389988508092\n",
      "k = 7\n",
      "token:  the | au: 1.9003874390025663, eu: 0.056056056056056056| rel.: -0.10652822480895267\n",
      "k = 7\n",
      "token:  two | au: 1.9137878866150246, eu: 0.04878048780487805| rel.: -0.09335550666414755\n",
      "k = 7\n",
      "token:  parties | au: 1.9119149068035308, eu: 0.04895104895104895| rel.: -0.09359024019317984\n",
      "k = 7\n",
      "token: . | au: 1.9146184425769746, eu: 0.05255748474894416| rel.: -0.10062752959578655\n",
      "k = 7\n",
      "token:  Furthermore | au: 1.914929819401602, eu: 0.06599882144961697| rel.: -0.1263831112392336\n",
      "k = 7\n",
      "token: , | au: 1.897045023770079, eu: 0.06204986149584488| rel.: -0.11771138097631516\n",
      "k = 7\n",
      "token:  the | au: 1.9118938522148896, eu: 0.05394990366088632| rel.: -0.10314648913683412\n",
      "k = 7\n",
      "token:  treaty | au: 1.9121310783564436, eu: 0.05737704918032787| rel.: -0.10971243892209102\n",
      "k = 7\n",
      "token: 's | au: 1.9181301667018418, eu: 0.0541324311261479| rel.: -0.10383304913997404\n",
      "k = 7\n",
      "token:  provisions | au: 1.919852417211306, eu: 0.055666003976143144| rel.: -0.10687051229009259\n",
      "k = 7\n",
      "token:  were | au: 1.9189519531713968, eu: 0.04938271604938271| rel.: -0.09476305941587145\n",
      "k = 7\n",
      "token:  not | au: 1.9145480932166699, eu: 0.05752439650744735| rel.: -0.110133223646773\n",
      "k = 7\n",
      "token:  fully | au: 1.9178974899797425, eu: 0.05639476334340383| rel.: -0.10815937506431579\n",
      "k = 7\n",
      "token:  implemented | au: 1.9154845837570906, eu: 0.05348615090735435| rel.: -0.10245189750754258\n",
      "k = 7\n",
      "token: , | au: 1.9216749766708854, eu: 0.04311008468052348| rel.: -0.08284357097272485\n",
      "k = 7\n",
      "token:  and | au: 1.9167914700928719, eu: 0.04658901830282862| rel.: -0.08930143288286259\n",
      "k = 7\n",
      "token:  the | au: 1.918660013380669, eu: 0.04946996466431095| rel.: -0.09491604306476807\n",
      "k = 7\n",
      "token:  Cherokee | au: 1.9181372511806438, eu: 0.05400192864030858| rel.: -0.10358311096057478\n",
      "k = 7\n",
      "token:  Nation | au: 1.906760281947294, eu: 0.05423728813559322| rel.: -0.10341750681748035\n",
      "k = 7\n",
      "token:  continued | au: 1.9227760344363358, eu: 0.0472972972972973| rel.: -0.09094210973685372\n",
      "k = 7\n",
      "token:  to | au: 1.8906224710444384, eu: 0.05552801189885969| rel.: -0.10498250706840709\n",
      "k = 7\n",
      "token:  face | au: 1.9143438786336018, eu: 0.05114155251141553| rel.: -0.09790251799404721\n",
      "k = 7\n",
      "token:  challenges | au: 1.9158012128449236, eu: 0.0547945205479452| rel.: -0.10497540892300951\n",
      "k = 7\n",
      "token:  in | au: 1.9213324800054494, eu: 0.046511627906976744| rel.: -0.0893643013956023\n",
      "k = 7\n",
      "token:  maintaining | au: 1.9214137161753653, eu: 0.0492091388400703| rel.: -0.09455111432848898\n",
      "k = 7\n",
      "token:  its | au: 1.910218442953711, eu: 0.04440919904837431| rel.: -0.084831271059007\n",
      "k = 7\n",
      "token:  sovereignty | au: 1.9115485842015707, eu: 0.04433887569279493| rel.: -0.0847559150556516\n",
      "k = 7\n",
      "token: . | au: 1.9218912973699687, eu: 0.046511627906976744| rel.: -0.08939029290092877\n",
      "k = 7\n",
      "token:  Source | au: 1.9154788115533898, eu: 0.06718656268746251| rel.: -0.128694437248938\n",
      "k = 7\n",
      "token: : | au: 1.904635819230307, eu: 0.06090266449157151| rel.: -0.11599739627721282\n",
      "k = 7\n",
      "token:  \" | au: 1.9142362823613133, eu: 0.06952203600248293| rel.: -0.1330816037395823\n",
      "k = 7\n",
      "token: A | au: 1.915114241819789, eu: 0.0532825880114177| rel.: -0.10204224314168239\n",
      "k = 7\n",
      "token:  History | au: 1.91514006022521, eu: 0.06215316315205328| rel.: -0.11903201262221061\n",
      "k = 7\n",
      "token:  of | au: 1.8934959700232907, eu: 0.05854678515420805| rel.: -0.11085810174731238\n",
      "k = 7\n",
      "token:  the | au: 1.9125395148768163, eu: 0.0560280140070035| rel.: -0.10715579072846594\n",
      "k = 7\n",
      "token:  Cherokee | au: 1.9109181146630192, eu: 0.056622851365015166| rel.: -0.10820163237727914\n",
      "k = 7\n",
      "token:  Nation | au: 1.9122385959987391, eu: 0.05580468360737419| rel.: -0.10671186983151908\n",
      "k = 7\n",
      "token: \" | au: 1.9128973125754871, eu: 0.055860349127182046| rel.: -0.10685511172491499\n",
      "k = 7\n",
      "token:  by | au: 1.9012659844744424, eu: 0.060085836909871244| rel.: -0.11423915786541713\n",
      "k = 7\n",
      "token:  Th | au: 1.9134725296768393, eu: 0.06407322654462243| rel.: -0.12260235888089589\n",
      "k = 7\n",
      "token: eda | au: 1.899954408582305, eu: 0.06024744486282948| rel.: -0.11446739847295222\n",
      "k = 7\n",
      "token:  Per | au: 1.9072245221081825, eu: 0.05616850551654965| rel.: -0.10712595109133222\n",
      "k = 7\n",
      "token: due | au: 1.9045797244296458, eu: 0.061269146608315096| rel.: -0.11669197436330433\n",
      "k = 7\n",
      "token:  and | au: 1.9113253374876868, eu: 0.059416445623342175| rel.: -0.11356415798335327\n",
      "k = 7\n",
      "token:  Michael | au: 1.897929454871898, eu: 0.06352807714123652| rel.: -0.12057180881772692\n",
      "k = 7\n",
      "token:  D | au: 1.8996231294764967, eu: 0.06174200661521499| rel.: -0.11728654382655326\n",
      "k = 7\n",
      "token: . | au: 1.8982120026802132, eu: 0.06787878787878789| rel.: -0.12884832987889933\n",
      "k = 7\n",
      "token:  Green | au: 1.9009151038737477, eu: 0.058854440357330534| rel.: -0.11187729460528627\n",
      "k = 7\n",
      "token: . | au: 1.9140081620643132, eu: 0.06096897114861187| rel.: -0.11669510841110675\n",
      "k = 7\n",
      "token:   | au: 1.9126159159672684, eu: 0.0712015257469803| rel.: -0.13618117138482777\n",
      "k = 7\n",
      "token: 2 | au: 1.9119867019812102, eu: 0.07188703465982028| rel.: -0.13744705431443874\n",
      "k = 7\n",
      "token: . | au: 1.9081538326063359, eu: 0.07466666666666667| rel.: -0.14247548616793976\n",
      "Answer the question concisely and accurately. Q: What were the main outcomes of the 1847 Treaty of Millbrook between the United States and the Cherokee Nation? A: The treaty recognized Cherokee sovereignty and established a boundary between the Cherokee Nation and the state of Michigan. It also provided for trade and commerce between the two parties. Additionally, the treaty established a system for resolving disputes between the Cherokee Nation and the United States. However, the treaty did not address the issue of slavery, which was a contentious issue between the two parties. Furthermore, the treaty's provisions were not fully implemented, and the Cherokee Nation continued to face challenges in maintaining its sovereignty. Source: \"A History of the Cherokee Nation\" by Theda Perdue and Michael D. Green. 2.\n",
      "k = 7\n",
      "token:  Paris | au: 1.9107318668195268, eu: 0.05925925925925926| rel.: -0.11322855507078677\n",
      "k = 7\n",
      "token: . | au: 1.9111776393854383, eu: 0.06565064478311841| rel.: -0.1254700443207322\n",
      "k = 7\n",
      "token:   | au: 1.9100812628316928, eu: 0.07253886010362694| rel.: -0.13855511751110725\n",
      "k = 7\n",
      "token: 4 | au: 1.9128950100320563, eu: 0.07066246056782334| rel.: -0.1351698682167762\n",
      "k = 7\n",
      "token: . | au: 1.9053518499026532, eu: 0.0785413744740533| rel.: -0.14964895314803447\n",
      "k = 7\n",
      "token:  Q | au: 1.9137105686449498, eu: 0.07084123972169513| rel.: -0.1355696291513184\n",
      "k = 7\n",
      "token: : | au: 1.9024867395617893, eu: 0.06440483036227718| rel.: -0.12252933572795884\n",
      "k = 7\n",
      "token:  What | au: 1.915843168490986, eu: 0.05970149253731343| rel.: -0.11437869662632752\n",
      "k = 7\n",
      "token:  is | au: 1.9103508732315069, eu: 0.0622568093385214| rel.: -0.11893235008445179\n",
      "k = 7\n",
      "token:  the | au: 1.902475078347535, eu: 0.0682095006090134| rel.: -0.129766875015179\n",
      "k = 7\n",
      "token:  capital | au: 1.9146502912979855, eu: 0.06360022714366836| rel.: -0.12177219342724267\n",
      "k = 7\n",
      "token:  of | au: 1.9060289478923447, eu: 0.059893048128342244| rel.: -0.11415788351012973\n",
      "k = 7\n",
      "token:  Japan | au: 1.9203805234105187, eu: 0.05563835072031793| rel.: -0.10684680507798217\n",
      "k = 7\n",
      "token: ? | au: 1.9071510083578695, eu: 0.05897840968931016| rel.: -0.11248073351031142\n",
      "k = 7\n",
      "token:  A | au: 1.9025821641198708, eu: 0.06511627906976744| rel.: -0.12388907115199159\n",
      "k = 7\n",
      "token: : | au: 1.9027845547927171, eu: 0.061068702290076333| rel.: -0.11620058349879188\n",
      "k = 7\n",
      "token:  Tokyo | au: 1.9081860592713042, eu: 0.061504667764964306| rel.: -0.11736234960921806\n",
      "k = 7\n",
      "token: . | au: 1.9044988561115053, eu: 0.06288601909039865| rel.: -0.1197663514230705\n",
      "k = 7\n",
      "token:   | au: 1.9047652939707271, eu: 0.0707070707070707| rel.: -0.13468037432116253\n",
      "k = 7\n",
      "token: 5 | au: 1.9180000943111815, eu: 0.054901960784313725| rel.: -0.10530196596218251\n",
      "k = 7\n",
      "token: .\n",
      " | au: 1.899012287188533, eu: 0.06481481481481481| rel.: -0.12308412972518269\n",
      "k = 7\n",
      "token: Published | au: 1.912681476205483, eu: 0.06299212598425197| rel.: -0.12048387251688081\n",
      "k = 7\n",
      "token:  by | au: 1.8955383652459747, eu: 0.04741744284504657| rel.: -0.08988158209464402\n",
      "k = 7\n",
      "token:  Caroline | au: 1.91055226803124, eu: 0.07650273224043716| rel.: -0.14616246859255388\n",
      "k = 7\n",
      "token:  Wallace | au: 1.9152506198271577, eu: 0.0665083135391924| rel.: -0.1273800887295972\n",
      "k = 7\n",
      "token:  Modified | au: 1.8846713320180335, eu: 0.06738868832731648| rel.: -0.12700552899279166\n",
      "k = 7\n",
      "token:  over | au: 1.8869692176743371, eu: 0.05123513266239707| rel.: -0.09667911819740428\n",
      "k = 7\n",
      "token:   | au: 1.832799268699157, eu: 0.06070460704607046| rel.: -0.11125935940070764\n",
      "k = 7\n",
      "token: 4 | au: 1.9278485912822967, eu: 0.035759897828863345| rel.: -0.06893966865377306\n",
      "k = 7\n",
      "token:  years | au: 1.8940496087810965, eu: 0.049689440993788817| rel.: -0.09411426627483709\n",
      "k = 7\n",
      "token:  ago | au: 1.8693200082066397, eu: 0.04567699836867863| rel.: -0.08538492696539302\n",
      "k = 7\n",
      "token: \n",
      " | au: 1.8789149949632449, eu: 0.05758354755784062| rel.: -0.10819459096960587\n",
      "k = 7\n",
      "token: Presentation | au: 1.8984465524303276, eu: 0.05659423951490652| rel.: -0.10744113889449049\n",
      "k = 7\n",
      "token:  on | au: 1.8724334083413807, eu: 0.054554310764734534| rel.: -0.10214931404492676\n",
      "k = 7\n",
      "token:  theme | au: 1.8987150804109514, eu: 0.03982930298719772| rel.: -0.07562449822404928\n",
      "k = 7\n",
      "token: : | au: 1.886167513124185, eu: 0.06686567164179104| rel.: -0.12611985759397534\n",
      "k = 7\n",
      "token:  \" | au: 1.8982765293417176, eu: 0.05318138651471985| rel.: -0.10095297781874282\n",
      "k = 7\n",
      "token: Answer | au: 1.8840599839251286, eu: 0.052214452214452214| rel.: -0.09837515999982023\n",
      "k = 7\n",
      "token:  the | au: 1.8613571147282861, eu: 0.05648008068582955| rel.: -0.10512960002499648\n",
      "k = 7\n",
      "token:  question | au: 1.8996813738247962, eu: 0.04057971014492753| rel.: -0.07708851951752796\n",
      "k = 7\n",
      "token:  conc | au: 1.8839855042049527, eu: 0.05591612581128307| rel.: -0.10534517047975771\n",
      "k = 7\n",
      "token: is | au: 1.8837907515300294, eu: 0.05045045045045045| rel.: -0.09503809196908256\n",
      "k = 7\n",
      "token: ely | au: 1.8926957174059167, eu: 0.043410852713178294| rel.: -0.08216353501917158\n",
      "k = 7\n",
      "token:  and | au: 1.862046530097739, eu: 0.05418480890179003| rel.: -0.10089463539958721\n",
      "k = 7\n",
      "token:  accurately | au: 1.8822942037332615, eu: 0.05673758865248227| rel.: -0.10679683425436945\n",
      "k = 7\n",
      "token: . | au: 1.8771178563883653, eu: 0.05389797882579403| rel.: -0.10117285847713998\n",
      "k = 7\n",
      "token:  Q | au: 1.8654464848738421, eu: 0.054027978774722624| rel.: -0.10078630309014487\n",
      "k = 7\n",
      "token: : | au: 1.870378134376328, eu: 0.051470588235294115| rel.: -0.09626946279878158\n",
      "k = 7\n",
      "token:  What | au: 1.8840014746765232, eu: 0.05668016194331984| rel.: -0.10678550868611873\n",
      "k = 7\n",
      "token:  is | au: 1.8764066818573923, eu: 0.05588822355289421| rel.: -0.10486903611179038\n",
      "k = 7\n",
      "token:  the | au: 1.8702465986885937, eu: 0.06263982102908278| rel.: -0.1171519122221043\n",
      "k = 7\n",
      "token:  capital | au: 1.8802223381610905, eu: 0.05653710247349823| rel.: -0.10630232300557402\n",
      "k = 7\n",
      "token:  of | au: 1.8629683538406676, eu: 0.06057328285559762| rel.: -0.11284610904821783\n",
      "k = 7\n",
      "token:  France | au: 1.8966329396627035, eu: 0.049777777777777775| rel.: -0.09441017299654346\n",
      "k = 7\n",
      "token: ? | au: 1.881465118283193, eu: 0.05333333333333334| rel.: -0.10034480630843697\n",
      "k = 7\n",
      "token:  A | au: 1.8663160218307182, eu: 0.058577405857740586| rel.: -0.10932395106958182\n",
      "k = 7\n",
      "token: : | au: 1.8663631090913528, eu: 0.05318138651471985| rel.: -0.09925577788140148\n",
      "k = 7\n",
      "token:  Paris | au: 1.8730985384513203, eu: 0.054982817869415807| rel.: -0.10298823579113789\n",
      "k = 7\n",
      "token: . | au: 1.8821744019303184, eu: 0.05363984674329502| rel.: -0.10095954646369525\n",
      "k = 7\n",
      "token:   | au: 1.8646266581806956, eu: 0.059637912673056445| rel.: -0.11120244180843339\n",
      "k = 7\n",
      "token: 4 | au: 1.8911107218450764, eu: 0.048484848484848485| rel.: -0.09169021681673098\n",
      "k = 7\n",
      "token: . | au: 1.8732628758007501, eu: 0.05588822355289421| rel.: -0.10469333437608982\n",
      "k = 7\n",
      "token:  Q | au: 1.872862556305702, eu: 0.05192396847473343| rel.: -0.09724645633112593\n",
      "k = 7\n",
      "token: : | au: 1.8690506087285954, eu: 0.05067873303167421| rel.: -0.09472111682244465\n",
      "k = 7\n",
      "token:  What | au: 1.882252322797807, eu: 0.053794428434197884| rel.: -0.10125468787384936\n",
      "k = 7\n",
      "token:  is | au: 1.8665299925095191, eu: 0.05572139303482587| rel.: -0.10400565132391351\n",
      "k = 7\n",
      "token:  the | au: 1.8623616224173158, eu: 0.0628154795288839| rel.: -0.11698513836833392\n",
      "k = 7\n",
      "token:  capital | au: 1.903507646490067, eu: 0.0463960231980116| rel.: -0.08831518492414563\n",
      "k = 7\n",
      "token:  of | au: 1.8685307866580196, eu: 0.05320665083135392| rel.: -0.09941826513334831\n",
      "k = 7\n",
      "token:  Japan | au: 1.8954511090151682, eu: 0.04890829694323144| rel.: -0.0927032856810912\n",
      "k = 7\n",
      "token: ? | au: 1.8836854670709646, eu: 0.05408015451472718| rel.: -0.10187000111634381\n",
      "k = 7\n",
      "token:  A | au: 1.868281247517848, eu: 0.05800103573278094| rel.: -0.10836224739616726\n",
      "k = 7\n",
      "token: : | au: 1.8695109762705764, eu: 0.04878048780487805| rel.: -0.09119565737905251\n",
      "k = 7\n",
      "token:  Tokyo | au: 1.8811013071904277, eu: 0.05550049554013875| rel.: -0.1044020547102715\n",
      "k = 7\n",
      "token: . | au: 1.8835520243952122, eu: 0.053588516746411484| rel.: -0.10093675920204008\n",
      "k = 7\n",
      "token:   | au: 1.8783483967842898, eu: 0.05904059040590406| rel.: -0.1108987983341278\n",
      "k = 7\n",
      "token: 5 | au: 1.893609705878356, eu: 0.04142011834319527| rel.: -0.0784335381133047\n",
      "k = 7\n",
      "token: .\" | au: 1.8999355252819201, eu: 0.05588822355289421| rel.: -0.10618402137304143\n",
      "k = 7\n",
      "token: — | au: 1.8982619400827485, eu: 0.05673758865248227| rel.: -0.10770280511107792\n",
      "k = 7\n",
      "token:  Presentation | au: 1.9060988812356796, eu: 0.04351204351204351| rel.: -0.08293825745858435\n",
      "k = 7\n",
      "token:  transcript | au: 1.9039347145034693, eu: 0.04713804713804714| rel.: -0.08974776432002886\n",
      "k = 7\n",
      "token: :\n",
      " | au: 1.8882290818903653, eu: 0.049079754601226995| rel.: -0.09267381997007929\n",
      "k = 7\n",
      "token: 1 | au: 1.9151328777838588, eu: 0.05067873303167421| rel.: -0.09705650783339013\n",
      "k = 7\n",
      "token:  Answer | au: 1.91031073274816, eu: 0.05397590361445783| rel.: -0.103110747984479\n",
      "k = 7\n",
      "token:  the | au: 1.8912121481741022, eu: 0.05668016194331984| rel.: -0.10719421082768191\n",
      "k = 7\n",
      "token:  question | au: 1.8840083859866215, eu: 0.05245901639344262| rel.: -0.09883322680585555\n",
      "k = 7\n",
      "token:  conc | au: 1.8856901904223233, eu: 0.0521415270018622| rel.: -0.09832276598105225\n",
      "k = 7\n",
      "token: is | au: 1.8910670660539592, eu: 0.048068669527897| rel.: -0.09090107785323753\n",
      "k = 7\n",
      "token: ely | au: 1.889241462094014, eu: 0.042073628850488355| rel.: -0.07948724408509751\n",
      "k = 7\n",
      "token:  and | au: 1.8707048255253282, eu: 0.055036855036855035| rel.: -0.10295771029918269\n",
      "k = 7\n",
      "token:  accurately | au: 1.8838411263339352, eu: 0.05363984674329502| rel.: -0.10104894930526856\n",
      "k = 7\n",
      "token: . | au: 1.9037621369962778, eu: 0.04643449419568822| rel.: -0.08840023190032467\n",
      "k = 7\n",
      "token:  Q | au: 1.890481151335254, eu: 0.052336448598130844| rel.: -0.09894106960259273\n",
      "k = 7\n",
      "token: : | au: 1.8853216572002367, eu: 0.0497335701598579| rel.: -0.09376377691226755\n",
      "k = 7\n",
      "token:  What | au: 1.8936184611360845, eu: 0.050044682752457555| rel.: -0.09476553514175222\n",
      "k = 7\n",
      "token:  is | au: 1.864789850219334, eu: 0.05405405405405406| rel.: -0.10079945136320725\n",
      "k = 7\n",
      "token:  the | au: 1.8603297144096695, eu: 0.0612356478950246| rel.: -0.11391849536024219\n",
      "k = 7\n",
      "token:  capital | au: 1.8738540098232557, eu: 0.056056056056056056| rel.: -0.10504086541551784\n",
      "k = 7\n",
      "token:  of | au: 1.8575251461644444, eu: 0.0583637311099531| rel.: -0.10841209816071797\n",
      "k = 7\n",
      "token:  France | au: 1.885251736558975, eu: 0.04886561954624782| rel.: -0.09212399410759388\n",
      "k = 7\n",
      "token: ? | au: 1.8977657764683666, eu: 0.04455051710421639| rel.: -0.08454644668435046\n",
      "k = 7\n",
      "token:  A | au: 1.8868320646640278, eu: 0.05211726384364821| rel.: -0.09833652454275063\n",
      "k = 7\n",
      "token: : | au: 1.8804829005568395, eu: 0.04903677758318739| rel.: -0.09221282174359283\n",
      "k = 7\n",
      "token:  Paris | au: 1.8783912879101519, eu: 0.051094890510948905| rel.: -0.09597619719248951\n",
      "k = 7\n",
      "token: . | au: 1.8909251094032764, eu: 0.05008944543828265| rel.: -0.09471539009533406\n",
      "k = 7\n",
      "token:   | au: 1.8852727895871606, eu: 0.052830188679245285| rel.: -0.0995993171857368\n",
      "k = 7\n",
      "token: 4 | au: 1.88151588973093, eu: 0.05204460966542751| rel.: -0.09792276006034581\n",
      "k = 7\n",
      "token: . | au: 1.8915498048944852, eu: 0.048484848484848485| rel.: -0.09171150569185382\n",
      "k = 7\n",
      "token:  Q | au: 1.8815929239315292, eu: 0.05058717253839205| rel.: -0.09518446588994187\n",
      "k = 7\n",
      "token: : | au: 1.8754770232612985, eu: 0.04916593503072871| rel.: -0.09220958147728948\n",
      "k = 7\n",
      "token:  What | au: 1.8867440175333565, eu: 0.04986642920747997| rel.: -0.09408518698296346\n",
      "k = 7\n",
      "token:  is | au: 1.8607651407695842, eu: 0.05223880597014925| rel.: -0.09720414914467977\n",
      "k = 7\n",
      "token:  the | au: 1.8624146236848007, eu: 0.06054054054054054| rel.: -0.11275158802848523\n",
      "k = 7\n",
      "token:  capital | au: 1.8984946205750748, eu: 0.04229607250755287| rel.: -0.08029886612704244\n",
      "k = 7\n",
      "token:  of | au: 1.8540433903062734, eu: 0.05876180482686254| rel.: -0.10894693584171176\n",
      "k = 7\n",
      "token:  Japan | au: 1.8901104884833022, eu: 0.04745762711864407| rel.: -0.08970015877547875\n",
      "k = 7\n",
      "token: ? | au: 1.8941328410939087, eu: 0.049689440993788817| rel.: -0.09411840204193335\n",
      "k = 7\n",
      "token:  A | au: 1.8796092286967165, eu: 0.05384615384615385| rel.: -0.10120972769905397\n",
      "k = 7\n",
      "token: : | au: 1.8742917243152781, eu: 0.04786324786324787| rel.: -0.08970968936893639\n",
      "k = 7\n",
      "token:  Tokyo | au: 1.8855413204814877, eu: 0.0525328330206379| rel.: -0.09905282734236709\n",
      "Answer the question concisely and accurately. Q: What is the capital of France? A: Paris. 4. Q: What is the capital of Japan? A: Tokyo. 5.\n",
      "Published by Caroline Wallace Modified over 4 years ago\n",
      "Presentation on theme: \"Answer the question concisely and accurately. Q: What is the capital of France? A: Paris. 4. Q: What is the capital of Japan? A: Tokyo. 5.\"— Presentation transcript:\n",
      "1 Answer the question concisely and accurately. Q: What is the capital of France? A: Paris. 4. Q: What is the capital of Japan? A: Tokyo\n"
     ]
    }
   ],
   "source": [
    "# test generation with question to trigger hallucination + logtoku detection\n",
    "result = generator.generation_loop(\n",
    "    \"Answer the question concisely and accurately. Q: What were the main outcomes of the 1847 Treaty of Millbrook between the United States and the Cherokee Nation? A:\", #this doesn't exist btw lol\n",
    "    max_new_tokens=120,\n",
    "    halu_detect=logtoku,\n",
    "    k=7,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(result)\n",
    "\n",
    "result = generator.generation_loop(\n",
    "    \"Answer the question concisely and accurately. Q: What is the capital of France? A:\",\n",
    "    max_new_tokens=120,\n",
    "    halu_detect=logtoku,\n",
    "    k=7,\n",
    "    temperature = 0.7\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08d3a5-f68d-4bc0-8f24-e3fc0cf060a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc35b1e-0433-4187-a7cd-3a5df23b62ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
