{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mpf6OEUFxmcA"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XyTbU2BFmZQy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "try: import spacy\n",
    "except ImportError:\n",
    "  os.system('pip install -U spacy')\n",
    "  os.system('python -m spacy download en_core_web_sm')\n",
    "  import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qfVhtPOQg9hQ"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "enHEZNiwk0eQ"
   },
   "outputs": [],
   "source": [
    "example = 'Have Apple stocks risen 40 million and what about Google stock?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7_v5sz8xwYd"
   },
   "source": [
    "# spacy fns\n",
    "lemmatization, entity extraction, noun phrase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qtrHBXP2kiWN"
   },
   "outputs": [],
   "source": [
    "# extract lemmas from text\n",
    "\n",
    "def get_lemmas(text):\n",
    "  doc = nlp(text)\n",
    "  return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTuwhFbzkxfn",
    "outputId": "a379ea95-b57b-4257-949e-dd9658a278db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have',\n",
       " 'Apple',\n",
       " 'stock',\n",
       " 'rise',\n",
       " '40',\n",
       " 'million',\n",
       " 'and',\n",
       " 'what',\n",
       " 'about',\n",
       " 'Google',\n",
       " 'stock',\n",
       " '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lemmas(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cao8OSt9hb8B"
   },
   "outputs": [],
   "source": [
    "# extract entities from text\n",
    "\n",
    "def get_ents(text):\n",
    "  doc = nlp(text)\n",
    "  return [ent.text for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrl42ioijThR",
    "outputId": "37c8cd7d-120a-49be-fceb-62ee82336af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple', '40 million', 'Google']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ents(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t5p1RMmCkPNZ"
   },
   "outputs": [],
   "source": [
    "# extract noun phrases from text\n",
    "\n",
    "def get_noun_phrases(text):\n",
    "  doc = nlp(text)\n",
    "  return [chunk.text for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0qPqJw5kczU",
    "outputId": "c1fd6312-f863-494b-f843-fe1872948112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple stocks', 'Google stock']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_noun_phrases(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xIqhkLZx4OS"
   },
   "source": [
    "# other fns\n",
    "cleaning text, filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ErLa8ujvubot"
   },
   "outputs": [],
   "source": [
    "# lower cases, strips, and removes punctuation from text\n",
    "\n",
    "def clean(text):\n",
    "  return text.lower().strip().translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mRYTO4E6rRgV"
   },
   "outputs": [],
   "source": [
    "# filters a text only for tokens that are in the filter text OR have a certain part of speech\n",
    "\n",
    "def filter_include(text, filter_txt, filter_pos):\n",
    "  doc = nlp(text)\n",
    "  return [token.text for token in doc if any(token.text in ft for ft in filter_txt) or token.pos_ in filter_pos]\n",
    "  #                                      ^ in filter text                              ^ certain part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFdJmNtPx-RB"
   },
   "source": [
    "# query editing\n",
    "query decomposition, query extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YFVHVvHZyDce"
   },
   "outputs": [],
   "source": [
    "# query decomposition\n",
    "# splits query by clauses\n",
    "\n",
    "def query_split(query):\n",
    "  doc = nlp(query)\n",
    "\n",
    "  # coordinating and subordinate conjunctions\n",
    "  conjs = ['CCONJ', 'SCONJ']\n",
    "\n",
    "  result = []\n",
    "  section = []\n",
    "  for token in doc:\n",
    "    if token.pos_ in conjs:\n",
    "      if section: # make sure section is not empty\n",
    "        result.append(' '.join(section))\n",
    "        section = []\n",
    "    else:\n",
    "      section.append(token.text)\n",
    "\n",
    "  if section:\n",
    "    result.append(' '.join(section)) # append final part\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elNcztjV0yc9",
    "outputId": "379c06f4-62e7-491a-b2d8-b30352ca63c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Have Apple stocks risen 40 million', 'what about Google stock ?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_split(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KOJWN_erjrdS"
   },
   "outputs": [],
   "source": [
    "# query extraction\n",
    "# takes lemmas and filters for entities and important parts of speech\n",
    "\n",
    "def query_extract(query):\n",
    "  lemmas = get_lemmas(query)\n",
    "  ents = get_ents(query)\n",
    "\n",
    "  important_text = ents\n",
    "  important_pos = ['NOUN', 'PROPN', 'VERB', 'ADJ', 'ADV']\n",
    "\n",
    "  lemmas = list(dict.fromkeys(lemmas)) # eliminates redundant elements\n",
    "  lemmas = filter_include(clean(str(lemmas)),\n",
    "                          important_text,\n",
    "                          important_pos) # filter\n",
    "\n",
    "  return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcZpOcwQw7kO",
    "outputId": "c0b5bdac-9222-4093-e502-97919b9a3a05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'stock', 'rise', '40', 'million', 'google']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_extract(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTqIvAkI2bwo",
    "outputId": "6df28d2a-3c4f-46ad-fe64-df4d2567c37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple stock rise 40 million\n",
      "google stock\n"
     ]
    }
   ],
   "source": [
    "# example with both fns\n",
    "\n",
    "for query in query_split(example):\n",
    "  print(' '.join(query_extract(query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFdJmNtPx-RB"
   },
   "source": [
    "# master fn\n",
    "full query transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full query transformation\n",
    "\n",
    "def query_transform(query = None):\n",
    "  '''\n",
    "  does full query transformation from user prompt to searcheable retrieval query\n",
    "\n",
    "  Args:\n",
    "    query (string, optional): The query to be processed. Will prompt user if not given or None\n",
    "  Returns:\n",
    "    list: A list of queries mentioned in the user's prompt, each lemmatized and extracted for entities, nouns, verbs, and modifiers\n",
    "  \n",
    "  '''\n",
    "    \n",
    "  query = input(\"Input query: \") if query is None else query\n",
    "    \n",
    "  transform_query = []\n",
    "  for sub_query in query_split(query):\n",
    "    transform_query.append(' '.join(query_extract(query)))\n",
    "      \n",
    "  return transform_query"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
